{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex feature selection as a preprocessing step to learning and clasification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dimensionality reduction and Clustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import manifold, datasets\n",
    "from itertools import cycle\n",
    "\n",
    "# Plotting tools and classifiers\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import LeaveOneOut\n",
    "\n",
    "# Let's read the data in and clean it\n",
    "\n",
    "def get_NaNs(df):\n",
    "    columns = list(df.columns.get_values()) \n",
    "    row_metrics = df.isnull().sum(axis=1)\n",
    "    rows_with_na = []\n",
    "    for i, x in enumerate(row_metrics):\n",
    "        if x > 0: rows_with_na.append(i)\n",
    "    return rows_with_na\n",
    "\n",
    "def remove_NaNs(df):\n",
    "    rows_with_na = get_NaNs(df)\n",
    "    cleansed_df = df.drop(df.index[rows_with_na], inplace=False)     \n",
    "    return cleansed_df\n",
    "\n",
    "initial_data = pd.DataFrame.from_csv('Data_Adults_1_reduced_inv4.csv')\n",
    "cleansed_df = remove_NaNs(initial_data)\n",
    "\n",
    "# Let's also get rid of nominal data\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "X = cleansed_df.select_dtypes(include=numerics)\n",
    "\n",
    "# Let's now clean columns getting rid of certain columns that might not be important to our analysis\n",
    "\n",
    "cols2drop = ['GROUP_ID', 'doa', 'Baseline_header_id', 'Concentration_header_id', 'Baseline_Reading_id',\n",
    "             'Concentration_Reading_id']\n",
    "X = X.drop(cols2drop, axis=1, inplace=False)\n",
    "\n",
    "# For our studies children skew the data, it would be cleaner to just analyse adults\n",
    "X = X.loc[X['Age'] >= 18]\n",
    "Y = X.loc[X['race_id'] == 1]\n",
    "X  = X.loc[X['Gender_id'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(946, 262)\n",
      "(223, 262)\n"
     ]
    }
   ],
   "source": [
    "# Let's extract ADHd and Bipolar patients (mutually exclusive)\n",
    "\n",
    "ADHD_men = X.loc[X['ADHD'] == 1]\n",
    "ADHD_men = ADHD_men.loc[ADHD_men['Bipolar'] == 0]\n",
    "\n",
    "BP_men = X.loc[X['Bipolar'] == 1]\n",
    "BP_men = BP_men.loc[BP_men['ADHD'] == 0]\n",
    "\n",
    "print ADHD_men.shape\n",
    "print BP_men.shape\n",
    "\n",
    "# Keeping a backup of the data frame object because numpy arrays don't play well with certain scikit functions\n",
    "ADHD_men = pd.DataFrame(ADHD_men.drop(['Patient_ID', 'Gender_id', 'ADHD', 'Bipolar', 'Age', 'race_id']\n",
    "                                      , axis = 1, inplace = False))\n",
    "BP_men = pd.DataFrame(BP_men.drop(['Patient_ID', 'Gender_id', 'ADHD', 'Bipolar', 'Age', 'race_id']\n",
    "                                  , axis = 1, inplace = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to explore Some feature selection procedures, the output of this will then be sent to a classifier\n",
    "\n",
    "1. Recursive elimination with cross validation\n",
    "2. Simple best percentile features\n",
    "3. Tree based feature selection\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "The output from this is then sent to  the following classifiers\n",
    "<br/>\n",
    "1. Random Forrests - Good ensemble technique\n",
    "2. QDA - Other experiments with this classifier have been successful\n",
    "3. LDA - A good simple technique\n",
    "4. Gaussian Naive Bayes - Experiments with this classifier have proven successful in the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Make the Labels vector\n",
    "clabels1 = [1] * 946 + [0] * 223\n",
    "\n",
    "# Concatenate and Scale\n",
    "combined1 = pd.concat([ADHD_men, BP_men])\n",
    "combined1 = pd.DataFrame(preprocessing.scale(combined1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Recursive Feature elimination with cross validation\n",
    "svc = SVC(kernel=\"linear\")\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(clabels1, 2),\n",
    "              scoring='accuracy')\n",
    "rfecv.fit(combined1, clabels1)\n",
    "combined1_recf = rfecv.transform(combined1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0  0.127190\n",
      "1  0.755222\n",
      "2 -0.977009\n",
      "3 -0.920686\n",
      "4  1.121645\n"
     ]
    }
   ],
   "source": [
    "combined1_recf = pd.DataFrame(combined1_recf)\n",
    "print combined1_recf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Percentile base feature selection \n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "selector = SelectPercentile(f_classif, percentile=5)\n",
    "combined_kpercentile = selector.fit_transform(combined1, clabels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6   \\\n",
      "0  0.169847 -0.209445 -0.275601 -0.666111 -0.693900 -0.106650 -0.896754   \n",
      "1  0.528386 -1.450367  0.845388  0.993640  0.548840  0.485510  0.881838   \n",
      "2 -0.114695  0.092482 -0.311967 -0.144872 -0.236797 -0.141822  0.176657   \n",
      "3 -0.328627 -0.195417 -0.914532 -0.715598 -0.795049 -0.979397 -0.366009   \n",
      "4 -1.798501 -0.282389  1.196440  1.232808  1.138202  0.632665  1.329041   \n",
      "\n",
      "         7         8         9         10        11        12  \n",
      "0  0.568321 -0.584540 -0.490285  0.244672 -0.656037 -0.125655  \n",
      "1  1.995632  0.687287  1.090067  0.663607  0.103919  0.242009  \n",
      "2 -0.270023 -0.271800 -1.089844 -1.227914 -0.745945 -0.586975  \n",
      "3 -0.295796 -0.403384 -1.374586 -1.591762 -1.334016 -0.257680  \n",
      "4 -0.222387  1.641005  2.128552  1.318883  1.785227  0.851758  \n"
     ]
    }
   ],
   "source": [
    "combined1_kpercentile = pd.DataFrame(combined_kpercentile)\n",
    "print combined1_kpercentile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tree based selection\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(combined1, clabels1)\n",
    "combined1_trees = SelectFromModel(clf, prefit=True).transform(combined1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.985856 -0.230012 -0.696085 -0.679657 -0.437323 -0.818528 -0.378125   \n",
      "1  1.008900  0.787332  0.587340  0.660063  0.897006  0.463454  0.579172   \n",
      "2 -0.202951 -0.240874 -0.090505 -0.253443 -0.258227 -0.460434 -0.397930   \n",
      "3 -1.710840 -0.819808 -0.929914 -1.020154 -1.212833 -1.107059 -1.410461   \n",
      "4  1.382728  0.950863  0.989392  0.796090  0.863338  1.492834  0.377695   \n",
      "\n",
      "        7         8         9      ...          113       114       115  \\\n",
      "0 -0.598823 -0.695587  0.169847    ...    -0.137138  0.692224 -0.261565   \n",
      "1  0.539337  0.362448  0.528386    ...     0.363758  1.061854  0.466651   \n",
      "2 -0.518928 -0.021714 -0.114695    ...    -0.813576 -0.604356 -1.194178   \n",
      "3 -1.497622 -0.728785 -0.328627    ...    -0.819188 -0.823223 -1.269110   \n",
      "4  1.605175 -2.591926 -1.798501    ...     2.538392  1.780245  2.345056   \n",
      "\n",
      "        116       117       118       119       120       121       122  \n",
      "0  0.473379 -0.209817 -0.599742 -0.214000  0.260055  0.547382  0.435904  \n",
      "1  1.353621  0.673496  0.338288  0.330374  0.437566  0.309658  0.098400  \n",
      "2 -1.264397 -1.477834 -1.054814 -0.535019 -0.998927 -1.003354 -0.738059  \n",
      "3 -1.216525 -1.466187 -1.149187 -1.933939 -1.208878 -1.562288 -1.587445  \n",
      "4  2.188733  1.304474  2.002857  2.187624  1.344800  0.644545  1.835503  \n",
      "\n",
      "[5 rows x 123 columns]\n"
     ]
    }
   ],
   "source": [
    "combined1_trees = pd.DataFrame(combined1_trees)\n",
    "print combined1_trees.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Leave one Out cross validation\n",
    "def leave_one_out(classifier, values, labels):\n",
    "    leave_one_out_validator = LeaveOneOut(len(values))\n",
    "    classifier_metrics = cross_validation.cross_val_score(classifier, values, labels, cv=leave_one_out_validator)\n",
    "    accuracy = classifier_metrics.mean()\n",
    "    deviation = classifier_metrics.std()\n",
    "    return accuracy, deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy is 0.6638 (+/- 0.472)\n",
      "LDA accuracy is 0.8092 (+/- 0.393)\n",
      "QDA accuracy is 0.8092 (+/- 0.393)\n",
      "Gaussian NB accuracy is 0.8092 (+/- 0.393)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 22) \n",
    "qda = QDA()\n",
    "lda = LDA()\n",
    "gnb = GaussianNB()\n",
    "classifier_accuracy_list = []\n",
    "classifiers = [(rf, \"Random Forest\"), (lda, \"LDA\"), (qda, \"QDA\"), (gnb, \"Gaussian NB\")]\n",
    "for classifier, name in classifiers:\n",
    "    accuracy, deviation = leave_one_out(classifier, combined1_recf, clabels1)\n",
    "    print '%s accuracy is %0.4f (+/- %0.3f)' % (name, accuracy, deviation)\n",
    "    classifier_accuracy_list.append((name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy is 0.8007 (+/- 0.399)\n",
      "LDA accuracy is 0.8084 (+/- 0.394)\n",
      "QDA accuracy is 0.7793 (+/- 0.415)\n",
      "Gaussian NB accuracy is 0.7990 (+/- 0.401)\n"
     ]
    }
   ],
   "source": [
    "for classifier, name in classifiers:\n",
    "    accuracy, deviation = leave_one_out(classifier, combined1_kpercentile, clabels1)\n",
    "    print '%s accuracy is %0.4f (+/- %0.3f)' % (name, accuracy, deviation)\n",
    "    classifier_accuracy_list.append((name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy is 0.7981 (+/- 0.401)\n",
      "LDA accuracy is 0.7819 (+/- 0.413)\n",
      "QDA accuracy is 0.8075 (+/- 0.394)\n",
      "Gaussian NB accuracy is 0.5141 (+/- 0.500)\n"
     ]
    }
   ],
   "source": [
    "for classifier, name in classifiers:\n",
    "    accuracy, deviation = leave_one_out(classifier, combined1_trees, clabels1)\n",
    "    print '%s accuracy is %0.4f (+/- %0.3f)' % (name, accuracy, deviation)\n",
    "    classifier_accuracy_list.append((name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
